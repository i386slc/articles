# Как отправлять сообщения Celery удаленному воркеру

{% hint style="info" %}
**Оригинальное название**: How to Send Celery Messages to Remote Worker

**Ссылка**: [https://coderbook.com/@marcus/how-to-send-celery-messages-to-remote-worker/](https://coderbook.com/@marcus/how-to-send-celery-messages-to-remote-worker/)

**Автор**: unknown

**Дата**: 22 января 2019
{% endhint %}

Когда вы настраиваете распределенную систему, в которой есть несколько различных приложений и служб, которые взаимодействуют друг с другом, вы можете выбрать несколько способов обработки этого взаимодействия.

Один из способов связи между службами, сохраняя при этом их несвязанность, — это отправка сообщений в очереди сообщений, которые другие службы получают и выполняют. Например, представьте, что у нас есть веб-приложение, которое позволяет пользователю загружать видео. Чтобы оптимизировать доставку и производительность потоковой передачи видео, мы можем преобразовать файлы в новый кодек или формат.

Задача преобразования видеофайлов в другой формат может быть возложена на вторую службу, не связанную с нашим веб-приложением. Таким образом, после того, как пользователь загрузит свой файл в наше хранилище, мы должны будем сообщить этому второму сервису, что он должен начать обработку загруженного файла.

Мы могли бы добиться этого с помощью веб-приложения, отправляющего сообщение воркеру второй службы с путем к файлу, требующему обработки, и затем мы можем позволить этому процессу происходить в фоновом режиме, пока мы продолжаем обслуживать наших посетителей и их веб-запросы из нашего сервиса веб-приложений. Отлично, правда?

Одним из наиболее популярных инструментов для управления такого рода сообщениями является Celery.

## Зачем использовать Celery вместо кастомного воркера?

Один из проектов, над которым я недавно работал в команде, требовал такого рода обработки сообщений, и мы решили создать свой собственный воркер, используя библиотеку обмена сообщениями **pika**. Идея написания собственных решений всегда весьма привлекательна для программистов, но в долгосрочной перспективе это вряд ли когда-либо будет правильным выбором — если только у вас нет каких-то очень специфических индивидуальных потребностей.

Довольно скоро мы столкнулись с некоторыми проблемами со стабильностью. Иногда время ожидания сообщений истекло, иногда у нас были проблемы с потоками, и в целом было довольно сложно отлаживать и устранять некоторые ошибки, которые были у нашего пользовательского воркера. Затем я предложил команде, что, возможно, было бы лучше переключиться на решение, которое было бы стабильным и готовым к использованию «из коробки» — **Celery**.

Зачем тратить время на поддержку собственных инструментов, когда все, что нам действительно нужно, — это что-то, что может отправлять, получать и обрабатывать сообщения? Это довольно просто и определенно не требует какого-либо специального решения. Добавьте к этому тот факт, что Celery получил более 10 000 коммитов, сотни участников и широко используется сообществом Django и Python в производственных средах, и он довольно быстро начинает выглядеть привлекательно.

Мы заменили наш собственный код и с тех пор не оглядывались назад.

## Разница между локальными и удаленными задачами

Большинство проектов не являются распределенными системами. В большинстве проектов используется только одно приложение с одним репозиторием кода. Это упрощает импорт и выполнение задач Celery следующим образом:

```python
from tasks.celery import app

@app.task
def sample_task(value):
    print(value)

sample_task.delay("Foo")
```

Мы можем просто импортировать функцию **sample\_task** и добавить к ней `.delay()`, чтобы вызывать ее как фоновую задачу, которая выполняется на нашем рабочем потоке. Но что, если у вас нет доступа к коду, в котором определена задача? Что, если он живет в совершенно другом репозитории и кодовой базе?

В случае распределенной системы с несколькими различными приложениями и репозиториями у каждого репозитория может быть свой собственный рабочий процесс Celery Worker и свои задачи. Вы не можете использовать python для импорта задачи из одной кодовой базы в другую.

В этой ситуации вы вызываете задачи по имени в строковом формате.

```python
from celery.tasks import app

app.send_task("sample_task", kwargs=dict(value="Foo"))
```

Это приводит к тому же действию, что и в первом примере сверху, но мы не требуем, чтобы фактическая функция была импортирована в наш код. Вместо этого мы можем просто вызвать его как строку. Также обратите внимание, что мы можем передавать любые аргументы ключевого слова, используя параметр `kwargs={}`.

## Направление задач в разные очереди

В случае нашего примера с распределенной системой нам может понадобиться запустить несколько рабочих процессов одновременно. Может быть, у нас есть Worker A для службы Service A и Worker B для Service B. Как нам убедиться, что каждый воркер не выполняет задачи друг друга?

Например, представьте, что мы отправляем сообщение для вызова **sample\_task**, определенного в разделе выше, но эта задача существует только внутри Worker A. Что произойдет, если Worker B получит сообщение первым? Это вызовет ошибку и будет утверждать, что задача еще не зарегистрирована и не может найти задачу.

Решение этой проблемы заключается в том, что мы разделяем очереди в зависимости от того, какой сервис Service или рабочий процесс Worker должен их обрабатывать. У нас может быть очередь `«worker_a»` и очередь `«worker_b»`, и Worker A будет слушать только сообщения от `«worker_a»`, а Worker B — только сообщения от `«worker_b»`.

Но как тогда убедиться, что каждое сообщение отправляется в правильную очередь? Это называется "Маршрутизация" (Routing).

## Маршрутизация сообщений в очереди на основе имени задачи

Celery позволяет нам определить **task\_routes**, куда он будет направлять сообщения в разные очереди в зависимости от имени задачи. Но для этого сначала потребуется, чтобы у нас был какой-то шаблон для нашего соглашения об именах задач, чтобы мы могли определить и создать правила, для которых задачи должны идти куда-то, основываясь на их именах.

Лично я предпочитаю ставить перед каждым именем задачи имя службы или приложения. Например, вместо определения задачи, как в первом примере, мы могли бы сделать это следующим образом.

```python
from tasks.celery import app

@app.task(name="web.sample_task")
def sample_task(value):
    print(value)
```

Обратите внимание, что мы добавили в нашу задачу параметр `name=""` с настраиваемым именем с префиксом `web.`, которое в данном случае будет представлять наше веб-приложение.

Сделав это, мы могли бы просто добавить конфигурацию **task\_routes**, которая гарантирует, что все задачи с префиксом `web.` переходит в **web\_queue**.

```python
app = Celery("proj")
# ...
app.conf.task_routes = {
    'web.*': {'queue': 'web_queue'}, 
    'remote.*': {'queue': 'remote_queue'}, 
}

```

Если у нас есть веб-воркер, который прослушивает очередь **web\_queue**, и удаленный рабочий процесс, который прослушивает очередь **remote\_queue**, мы всегда будем уверены, что нужный рабочий процесс получит правильное сообщение.

## Настройка бэкенда результатов

До сих пор конфигурация позволяла нам отправлять сообщения только воркерам в распределенной системе. Но как насчет отслеживания результатов? Прямо сейчас мы бы просто рассылали сообщения, не зная, что с ними происходит. Они преуспели или потерпели неудачу? Какие значения вернуло сообщение?

Способ, которым Celery отслеживает результаты и статус сообщений, заключается в определении «бэкенда результатов» (Result Backend). Серверная часть результата определяет, как и где Celery должен хранить метаданные задачи. Это может быть в базе данных, такой как PostgreSQL и Redis, или это может быть просто _**возврат данных клиенту**_ через протокол `amqp://`.

Если у вас есть только один рабочий процесс, который является частью остальной части вашего приложения, я предлагаю вам использовать серверную часть базы данных или [django-celery-results](https://github.com/celery/django-celery-results), чтобы вы могли хранить данные в базе данных или легко настроить сигналы Django для запуска обратных вызовов. всякий раз, когда задача выполняется успешно.

Однако, если у вас есть несколько рабочих процессов в распределенной системе, важно отметить, что каждый рабочий процесс должен использовать один и тот же сервер результатов. Если клиент и рабочий процесс не используют один и тот же сервер результатов, клиент никогда не получит никакого ответа или результата от своих сообщений.

Поскольку всем работникам в распределенной системе требуется один и тот же сервер результатов, это означает, что любой сервер, который вы выберете, _**должен быть доступен во всей вашей системе**_. Это может добавить более тесную связь между вашими сервисами, чего вы, возможно, не хотите. Из-за этого я предпочитаю использовать серверную часть **rpc**, что означает, что любой ответ будет возвращен по протоколу `amqp://` обратно клиенту, отправившему сообщение.

Это означает, что ваш клиент может определить, что делать с ответом вручную, вместо автоматического сохранения результатов или ответов в базе данных или экземпляре Redis.

Вы определяете серверную часть **rpc** со следующей конфигурацией

```python
CELERY_RESULT_BACKEND = 'rpc'
```

## Резюме

В этой статье мы узнали несколько разных вещей о том, как правильно настроить Celery для работы в распределенной системе, где у нас может быть несколько разных рабочих процессов, которые обрабатывают задачи, распределенные между несколькими кодовыми базами. Из этого мы можем узнать следующее:

* Определение очереди для каждого типа рабочего процесса, чтобы правильные задачи выполнялись только нужным воркерами.
* Направление сообщения в очереди на основе их имен. Убедитесь, что ваши задачи имеют префиксы, чтобы было легко определить правила маршрутизатора.
* Использование **RESULT\_BACKEND**, который доступен во всей вашей системе. Если вы хотите, чтобы вещи были разделены и не полагались на какое-то глобальное хранилище, используйте бэкэнд **rpc**, который будет возвращать результаты обратно через протокол `amqp://`.
